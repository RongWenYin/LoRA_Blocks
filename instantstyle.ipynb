{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9206661,"sourceType":"datasetVersion","datasetId":5566656},{"sourceId":9426915,"sourceType":"datasetVersion","datasetId":5726560},{"sourceId":9474077,"sourceType":"datasetVersion","datasetId":5761810},{"sourceId":9475039,"sourceType":"datasetVersion","datasetId":5762487},{"sourceId":9478044,"sourceType":"datasetVersion","datasetId":5764781}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"No need to run ,it may exceed the diskspace. Need restart","metadata":{}},{"cell_type":"code","source":"import os\n# Set the environment variable\nos.environ['HF_HOME'] = \"/kaggle/working/cache/\"\nprint('done')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip -q install huggingface_hub diffusers einops","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Clone the InstantStyle repository\n!git clone https://github.com/InstantStyle/InstantStyle.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Change directory to InstantStyle\n%cd InstantStyle","metadata":{"execution":{"iopub.status.busy":"2024-10-14T22:19:49.504869Z","iopub.execute_input":"2024-10-14T22:19:49.505598Z","iopub.status.idle":"2024-10-14T22:19:49.518417Z","shell.execute_reply.started":"2024-10-14T22:19:49.505554Z","shell.execute_reply":"2024-10-14T22:19:49.517469Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/working/InstantStyle\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Local Lora:**","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import hf_hub_download\nimport os\nstyle_B_LoRA_path=hf_hub_download(repo_id=\"ElaineYin/fangao1\", filename=\"f1_1000.safetensors\", local_dir=\"lora100\")\nprint(style_B_LoRA_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import hf_hub_download\nimport os\nip_ckpt=hf_hub_download(repo_id=\"h94/IP-Adapter\", filename=\"sdxl_models/ip-adapter_sdxl.bin\", local_dir=\"ipadapter\")\nprint(ip_ckpt)\nhf_hub_download(repo_id=\"h94/IP-Adapter\", filename=\"sdxl_models/image_encoder/config.json\", local_dir=\"ipadapter\")\nhf_hub_download(repo_id=\"h94/IP-Adapter\", filename=\"sdxl_models/image_encoder/pytorch_model.bin\", local_dir=\"ipadapter\")\nimage_encoder_file_path=hf_hub_download(repo_id=\"h94/IP-Adapter\", filename=\"sdxl_models/image_encoder/model.safetensors\", local_dir=\"ipadapter\")\n# Get the parent folder of the file\nimage_encoder_path = os.path.dirname(image_encoder_file_path)\n\n# Print the parent folder\nprint(image_encoder_path)\n# hf_hub_download(repo_id=\"h94/IP-Adapter\", filename=\"sdxl_models/image_encoder/config.json\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ip_ckpt='ipadapter/sdxl_models/ip-adapter_sdxl.bin'\nprint(ip_ckpt)\nimage_encoder_path='ipadapter/sdxl_models/image_encoder'\nprint(image_encoder_path)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T22:19:52.562935Z","iopub.execute_input":"2024-10-14T22:19:52.563641Z","iopub.status.idle":"2024-10-14T22:19:52.568550Z","shell.execute_reply.started":"2024-10-14T22:19:52.563601Z","shell.execute_reply":"2024-10-14T22:19:52.567552Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"ipadapter/sdxl_models/ip-adapter_sdxl.bin\nipadapter/sdxl_models/image_encoder\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom diffusers import StableDiffusionXLPipeline\nfrom PIL import Image\n\nfrom ip_adapter import IPAdapterXL\n\nBLOCKS_M = {\n    # target_blocks=[\"block\"] for original IP-Adapter\n    # target_blocks=[\"up_blocks.0.attentions.1\"] for style blocks only\n    # target_blocks = [\"up_blocks.0.attentions.1\", \"down_blocks.2.attentions.1\"] # for style+layout blocks\n    \n    'ALL': ['block'],\n    'Wm1':['down_blocks.1.attentions.0'],\n    'W0':['down_blocks.1.attentions.1'],\n    'W1':['down_blocks.2.attentions.0'],\n    'W2':['down_blocks.2.attentions.1'],\n    'W3':['mid_block.attentions.0'],\n    'W4':['up_blocks.0.attentions.0'],\n    'W5':['up_blocks.0.attentions.1'],\n    'W6':['up_blocks.0.attentions.2'],\n    'W7':['up_blocks.1.attentions.0'],\n    'W8':['up_blocks.1.attentions.1'],\n    'W9':['up_blocks.1.attentions.2'],\n    \n    'W20':['down_blocks.2.attentions.1.transformer_blocks.0'],\n    'W21':['down_blocks.2.attentions.1.transformer_blocks.1'],\n    'W22':['down_blocks.2.attentions.1.transformer_blocks.2'],\n    'W23':['down_blocks.2.attentions.1.transformer_blocks.3'],\n    'W24':['down_blocks.2.attentions.1.transformer_blocks.4'],\n    'W25':['down_blocks.2.attentions.1.transformer_blocks.5'],\n    'W26':['down_blocks.2.attentions.1.transformer_blocks.6'],\n    'W27':['down_blocks.2.attentions.1.transformer_blocks.7'],\n    'W28':['down_blocks.2.attentions.1.transformer_blocks.8'],\n    'W29':['down_blocks.2.attentions.1.transformer_blocks.9'],\n    'W50':['up_blocks.0.attentions.1.transformer_blocks.0'],\n    'W51':['up_blocks.0.attentions.1.transformer_blocks.1'],\n    'W52':['up_blocks.0.attentions.1.transformer_blocks.2'],\n    'W53':['up_blocks.0.attentions.1.transformer_blocks.3'],\n    'W54':['up_blocks.0.attentions.1.transformer_blocks.4'],\n    'W55':['up_blocks.0.attentions.1.transformer_blocks.5'],\n    'W56':['up_blocks.0.attentions.1.transformer_blocks.6'],\n    'W57':['up_blocks.0.attentions.1.transformer_blocks.7'],\n    'W58':['up_blocks.0.attentions.1.transformer_blocks.8'],\n    'W59':['up_blocks.0.attentions.1.transformer_blocks.9'],\n    'W60':['up_blocks.0.attentions.2.transformer_blocks.0'],\n    'W61':['up_blocks.0.attentions.2.transformer_blocks.1'],\n    'W62':['up_blocks.0.attentions.2.transformer_blocks.2'],\n    'W63':['up_blocks.0.attentions.2.transformer_blocks.3'],\n    'W64':['up_blocks.0.attentions.2.transformer_blocks.4'],\n    'W65':['up_blocks.0.attentions.2.transformer_blocks.5'],\n    'W66':['up_blocks.0.attentions.2.transformer_blocks.6'],\n    'W67':['up_blocks.0.attentions.2.transformer_blocks.7'],\n    'W68':['up_blocks.0.attentions.2.transformer_blocks.8'],\n    'W69':['up_blocks.0.attentions.2.transformer_blocks.9'],\n    \n}\nbase_model_path = \"stabilityai/stable-diffusion-xl-base-1.0\"\n# image_encoder_path = \"sdxl_models/image_encoder\"\n# ip_ckpt = \"sdxl_models/ip-adapter_sdxl.bin\"\ndevice = \"cuda\"\n\n# Function to free up GPU memory\ndef freeCache(pipeline):\n    try:\n        del pipeline  # Delete the pipeline object if it exists\n#         print(\"Pipeline deleted to free up GPU memory.\")\n    except NameError:\n        print(\"Pipeline does not exist, no need to delete.\")\n    except Exception as e:\n        print(f\"An error occurred when trying to delete pipeline: {e}\")\n    \n    torch.cuda.empty_cache()  # Clear the GPU memory\n    \n# Optionally clear cache for transformers\nimport transformers\ntransformers.utils.move_cache()\n    \ndef genImg(layers,refImg,styleKey,objectNames,neg_conten_prompt=''):\n    layerList=layers.split('_')\n    \n    blocks=[]\n    for lay in layerList:\n        blocks.extend(BLOCKS_M[lay])\n        \n    # load SDXL pipeline\n    pipe = StableDiffusionXLPipeline.from_pretrained(\n        base_model_path,\n        torch_dtype=torch.float16,\n        add_watermarker=False,\n    )\n\n    # reduce memory consumption\n    pipe.enable_vae_tiling()\n    \n#     target_blocks=BLOCKS_M[block_key]\n    # load ip-adapter\n    ip_model = IPAdapterXL(pipe, image_encoder_path, \n                           ip_ckpt, device, target_blocks=blocks)\n\n#     image = \"./assets/0.jpg\"\n    image = Image.open(refImg)\n    image.resize((512, 512))\n    \n#     neg_content_scaleli=[0.5,0.7]\n    neg_content_scaleli=[0.3,0.5,0.7]\n    negative_prompt= f'text, watermark, lowres, low quality, worst quality, deformed, glitch, low contrast, noisy, saturation, blurry'\n    print('negative_prompt :',negative_prompt,\" neg_conten_prompt:\",neg_conten_prompt)\n    for neg_content_scale in neg_content_scaleli:\n        for objectName in objectNames:\n            # generate image variations with only image prompt\n            images = ip_model.generate(pil_image=image,\n                                        prompt=f'a {objectName}, masterpiece, best quality, high quality',\n                                        negative_prompt= negative_prompt,\n                                        scale=1.0,\n                                        guidance_scale=5,\n                                        num_samples=1,\n                                        num_inference_steps=30, \n                                        seed=42,\n                                        neg_content_prompt=f'{neg_conten_prompt}',\n                                        neg_content_scale=neg_content_scale,\n                                      )\n            print(f' done layer: {layers}')\n            images[0].save(f'{styleKey}__{neg_conten_prompt}_{str(neg_content_scale)}_ins_{objectName}_{layers}_1000.png')\n            freeCache(pipe)\n","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-10-14T22:31:00.119353Z","iopub.execute_input":"2024-10-14T22:31:00.119743Z","iopub.status.idle":"2024-10-14T22:31:00.153632Z","shell.execute_reply.started":"2024-10-14T22:31:00.119704Z","shell.execute_reply":"2024-10-14T22:31:00.152744Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"604d89418d8b406cad6217e55fcba104"}},"metadata":{}}]},{"cell_type":"code","source":"layerList=['W2_W5']\n# layerList=['W2_W5','W5']\n# layerList=['Wm1','W0','W7','W8','W9',\n#           'Wm1_W0','Wm1_W1','Wm1_W2','Wm1_W3','Wm1_W4','Wm1_W5','Wm1_W6','Wm1_W7','Wm1_W8','Wm1_W9',\n#           'W0_W1','W0_W2','W0_W3','W0_W4','W0_W5','W0_W6','W0_W7','W0_W8','W0_W9',\n#           'W1_W7','W1_W8','W1_W9',\n#           'W2_W7','W2_W8','W2_W9',\n#           'W3_W7','W3_W8','W3_W9',\n#           'W4_W7','W4_W8','W4_W9',\n#           'W5_W7','W5_W8','W5_W9',\n#           'W6_W7','W6_W8','W6_W9',\n#           'W7_W8','W7_W9',\n#           'W8_W9',\n#           'W1','W2','W3','W4','W5','W6','W1_W2','W1_W3','W1_W4','W1_W5','W1_W6','W2_W3','W2_W4','W2_W5','W2_W6','W3_W4','W3_W5','W3_W6','W4_W5','W4_W6','W5_W6'\n#          ]\n# layerList=[\n# 'W20','W20_W21','W20_W21_W22','W20_W21_W22_W23','W20_W21_W22_W23_W24','W20_W21_W22_W23_W24_W25','W20_W21_W22_W23_W24_W25_W26','W20_W21_W22_W23_W24_W25_W26_W27','W20_W21_W22_W23_W24_W25_W26_W27_W28','W20_W21_W22_W23_W24_W25_W26_W27_W28_W29',\n# 'W21','W21_W22','W21_W22_W23','W21_W22_W23_W24','W21_W22_W23_W24_W25','W21_W22_W23_W24_W25_W26','W21_W22_W23_W24_W25_W26_W27','W21_W22_W23_W24_W25_W26_W27_W28','W21_W22_W23_W24_W25_W26_W27_W28_W29',\n# 'W22','W22_W23','W22_W23_W24','W22_W23_W24_W25','W22_W23_W24_W25_W26','W22_W23_W24_W25_W26_W27','W22_W23_W24_W25_W26_W27_W28','W22_W23_W24_W25_W26_W27_W28_W29',\n# 'W23','W23_W24','W23_W24_W25','W23_W24_W25_W26','W23_W24_W25_W26_W27','W23_W24_W25_W26_W27_W28','W23_W24_W25_W26_W27_W28_W29',\n# 'W24','W24_W25','W24_W25_W26','W24_W25_W26_W27','W24_W25_W26_W27_W28','W24_W25_W26_W27_W28_W29',\n# 'W25','W25_W26','W25_W26_W27','W25_W26_W27_W28','W25_W26_W27_W28_W29',\n# 'W26','W26_W27','W26_W27_W28','W26_W27_W28_W29',\n# 'W27','W27_W28','W27_W28_W29',\n# 'W28','W28_W29'\n# ]\n# layerList=[\n# 'W50','W50_W51','W50_W51_W52','W50_W51_W52_W53','W50_W51_W52_W53_W54','W50_W51_W52_W53_W54_W55','W50_W51_W52_W53_W54_W55_W56','W50_W51_W52_W53_W54_W55_W56_W57','W50_W51_W52_W53_W54_W55_W56_W57_W58','W50_W51_W52_W53_W54_W55_W56_W57_W58_W59',\n# 'W51','W51_W52','W51_W52_W53','W51_W52_W53_W54','W51_W52_W53_W54_W55','W51_W52_W53_W54_W55_W56','W51_W52_W53_W54_W55_W56_W57','W51_W52_W53_W54_W55_W56_W57_W58','W51_W52_W53_W54_W55_W56_W57_W58_W59',\n# 'W52','W52_W53','W52_W53_W54','W52_W53_W54_W55','W52_W53_W54_W55_W56','W52_W53_W54_W55_W56_W57','W52_W53_W54_W55_W56_W57_W58','W52_W53_W54_W55_W56_W57_W58_W59',\n# 'W53','W53_W54','W53_W54_W55','W53_W54_W55_W56','W53_W54_W55_W56_W57','W53_W54_W55_W56_W57_W58','W53_W54_W55_W56_W57_W58_W59',\n# 'W54','W54_W55','W54_W55_W56','W54_W55_W56_W57','W54_W55_W56_W57_W58','W54_W55_W56_W57_W58_W59',\n# 'W55','W55_W56','W55_W56_W57','W55_W56_W57_W58','W55_W56_W57_W58_W59',\n# 'W56','W56_W57','W56_W57_W58','W56_W57_W58_W59',\n# 'W57','W57_W58','W57_W58_W59',\n# 'W58','W58_W59'\n# ]\n# layerList=[\n# 'W50','W50_W51','W50_W51_W52','W50_W51_W52_W53','W50_W51_W52_W53_W54','W50_W51_W52_W53_W54_W55','W50_W51_W52_W53_W54_W55_W56','W50_W51_W52_W53_W54_W55_W56_W57','W50_W51_W52_W53_W54_W55_W56_W57_W58','W50_W51_W52_W53_W54_W55_W56_W57_W58_W59','W50_W51_W52_W53_W54_W55_W56_W57_W58_W59_W60','W50_W51_W52_W53_W54_W55_W56_W57_W58_W59_W60_W61','W50_W51_W52_W53_W54_W55_W56_W57_W58_W59_W60_W61_W62','W50_W51_W52_W53_W54_W55_W56_W57_W58_W59_W60_W61_W62_W63','W50_W51_W52_W53_W54_W55_W56_W57_W58_W59_W60_W61_W62_W63_W64',\n# 'W51','W51_W52','W51_W52_W53','W51_W52_W53_W54','W51_W52_W53_W54_W55','W51_W52_W53_W54_W55_W56','W51_W52_W53_W54_W55_W56_W57','W51_W52_W53_W54_W55_W56_W57_W58','W51_W52_W53_W54_W55_W56_W57_W58_W59','W51_W52_W53_W54_W55_W56_W57_W58_W59_W60','W51_W52_W53_W54_W55_W56_W57_W58_W59_W60_W61','W51_W52_W53_W54_W55_W56_W57_W58_W59_W60_W61_W62','W51_W52_W53_W54_W55_W56_W57_W58_W59_W60_W61_W62_W63','W51_W52_W53_W54_W55_W56_W57_W58_W59_W60_W61_W62_W63_W64',\n# 'W52','W52_W53','W52_W53_W54','W52_W53_W54_W55','W52_W53_W54_W55_W56','W52_W53_W54_W55_W56_W57','W52_W53_W54_W55_W56_W57_W58','W52_W53_W54_W55_W56_W57_W58_W59','W52_W53_W54_W55_W56_W57_W58_W59_W60','W52_W53_W54_W55_W56_W57_W58_W59_W60_W61','W52_W53_W54_W55_W56_W57_W58_W59_W60_W61_W62','W52_W53_W54_W55_W56_W57_W58_W59_W60_W61_W62_W63','W52_W53_W54_W55_W56_W57_W58_W59_W60_W61_W62_W63_W64',\n# 'W53','W53_W54','W53_W54_W55','W53_W54_W55_W56','W53_W54_W55_W56_W57','W53_W54_W55_W56_W57_W58','W53_W54_W55_W56_W57_W58_W59','W53_W54_W55_W56_W57_W58_W59_W60','W53_W54_W55_W56_W57_W58_W59_W60_W61','W53_W54_W55_W56_W57_W58_W59_W60_W61_W62','W53_W54_W55_W56_W57_W58_W59_W60_W61_W62_W63','W53_W54_W55_W56_W57_W58_W59_W60_W61_W62_W63_W64',\n# 'W54','W54_W55','W54_W55_W56','W54_W55_W56_W57','W54_W55_W56_W57_W58','W54_W55_W56_W57_W58_W59','W54_W55_W56_W57_W58_W59_W60','W54_W55_W56_W57_W58_W59_W60_W61','W54_W55_W56_W57_W58_W59_W60_W61_W62','W54_W55_W56_W57_W58_W59_W60_W61_W62_W63','W54_W55_W56_W57_W58_W59_W60_W61_W62_W63_W64',\n# 'W55','W55_W56','W55_W56_W57','W55_W56_W57_W58','W55_W56_W57_W58_W59','W55_W56_W57_W58_W59_W60','W55_W56_W57_W58_W59_W60_W61','W55_W56_W57_W58_W59_W60_W61_W62','W55_W56_W57_W58_W59_W60_W61_W62_W63','W55_W56_W57_W58_W59_W60_W61_W62_W63_W64',\n# 'W56','W56_W57','W56_W57_W58','W56_W57_W58_W59','W56_W57_W58_W59_W60','W56_W57_W58_W59_W60_W61','W56_W57_W58_W59_W60_W61_W62','W56_W57_W58_W59_W60_W61_W62_W63','W56_W57_W58_W59_W60_W61_W62_W63_W64',\n# 'W57','W57_W58','W57_W58_W59','W57_W58_W59_W60','W57_W58_W59_W60_W61','W57_W58_W59_W60_W61_W62','W57_W58_W59_W60_W61_W62_W63','W57_W58_W59_W60_W61_W62_W63_W64',\n# 'W58','W58_W59','W58_W59_W60','W58_W59_W60_W61','W58_W59_W60_W61_W62','W58_W59_W60_W61_W62_W63','W58_W59_W60_W61_W62_W63_W64'\n# ]\n# layerList=[\n# 'W50_W51_W52_W53_W54_W55_W56_W57_W58_W59_W60','W50_W51_W52_W53_W54_W55_W56_W57_W58_W59_W60_W61','W50_W51_W52_W53_W54_W55_W56_W57_W58_W59_W60_W61_W62','W50_W51_W52_W53_W54_W55_W56_W57_W58_W59_W60_W61_W62_W63','W50_W51_W52_W53_W54_W55_W56_W57_W58_W59_W60_W61_W62_W63_W64',\n# 'W51_W52_W53_W54_W55_W56_W57_W58_W59_W60','W51_W52_W53_W54_W55_W56_W57_W58_W59_W60_W61','W51_W52_W53_W54_W55_W56_W57_W58_W59_W60_W61_W62','W51_W52_W53_W54_W55_W56_W57_W58_W59_W60_W61_W62_W63','W51_W52_W53_W54_W55_W56_W57_W58_W59_W60_W61_W62_W63_W64',\n# 'W52_W53_W54_W55_W56_W57_W58_W59_W60','W52_W53_W54_W55_W56_W57_W58_W59_W60_W61','W52_W53_W54_W55_W56_W57_W58_W59_W60_W61_W62','W52_W53_W54_W55_W56_W57_W58_W59_W60_W61_W62_W63','W52_W53_W54_W55_W56_W57_W58_W59_W60_W61_W62_W63_W64',\n# 'W53_W54_W55_W56_W57_W58_W59_W60','W53_W54_W55_W56_W57_W58_W59_W60_W61','W53_W54_W55_W56_W57_W58_W59_W60_W61_W62','W53_W54_W55_W56_W57_W58_W59_W60_W61_W62_W63','W53_W54_W55_W56_W57_W58_W59_W60_W61_W62_W63_W64',\n# 'W54_W55_W56_W57_W58_W59_W60','W54_W55_W56_W57_W58_W59_W60_W61','W54_W55_W56_W57_W58_W59_W60_W61_W62','W54_W55_W56_W57_W58_W59_W60_W61_W62_W63','W54_W55_W56_W57_W58_W59_W60_W61_W62_W63_W64',\n# 'W55_W56_W57_W58_W59_W60','W55_W56_W57_W58_W59_W60_W61','W55_W56_W57_W58_W59_W60_W61_W62','W55_W56_W57_W58_W59_W60_W61_W62_W63','W55_W56_W57_W58_W59_W60_W61_W62_W63_W64',\n# 'W56_W57_W58_W59_W60','W56_W57_W58_W59_W60_W61','W56_W57_W58_W59_W60_W61_W62','W56_W57_W58_W59_W60_W61_W62_W63','W56_W57_W58_W59_W60_W61_W62_W63_W64',\n# 'W57_W58_W59_W60','W57_W58_W59_W60_W61','W57_W58_W59_W60_W61_W62','W57_W58_W59_W60_W61_W62_W63','W57_W58_W59_W60_W61_W62_W63_W64',\n# 'W58_W59_W60','W58_W59_W60_W61','W58_W59_W60_W61_W62','W58_W59_W60_W61_W62_W63','W58_W59_W60_W61_W62_W63_W64'\n# ]\n# layerList=['W58_W59_W60_W61_W62','W58_W59_W60_W61_W62_W63','W58_W59_W60_W61_W62_W63_W64']\n#TMP\n# layerList=['W22_W23_W24_W25_W26_W27_W28_W29']\n# layerList=['W1_W2','W1_W3','W1_W4','W1_W5','W1_W6','W2_W6','W5_W6']\n# refImg='/kaggle/input/img-f2/f2.PNG'\n# refImg='/kaggle/input/img-grape/grape.png'\n# styleKey='grape'\n# neg_conten_prompt='grape'\n# refImg='/kaggle/input/style-view/Weixin Image_20240511110827.png'\n# neg_conten_prompt='people'\n# styleKey='aut'\n# refImg='/kaggle/input/img-bajiao/bajiao.png'\n# neg_conten_prompt='girl'\n# styleKey='bajiao'\nrefImg='/kaggle/input/img-colorbuilding/color_building.png'\nstyleKey='colorbuilding'\nneg_conten_prompt='tower'\nobjectNames=['apple','dog','girl','fish','cat']\nfor layers in layerList:\n    genImg(layers,refImg,styleKey,objectNames,neg_conten_prompt)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T22:31:13.544777Z","iopub.execute_input":"2024-10-14T22:31:13.545206Z","iopub.status.idle":"2024-10-14T22:40:47.798549Z","shell.execute_reply.started":"2024-10-14T22:31:13.545167Z","shell.execute_reply":"2024-10-14T22:40:47.797466Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b88b97327ee4251a3caff79d640a096"}},"metadata":{}},{"name":"stdout","text":"negative_prompt : text, watermark, lowres, low quality, worst quality, deformed, glitch, low contrast, noisy, saturation, blurry  neg_conten_prompt: tower\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdec7de609c44f0fa8fe80340369f19a"}},"metadata":{}},{"name":"stdout","text":" done layer: W2_W5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d2130e44c554662a5aa05e185923520"}},"metadata":{}},{"name":"stdout","text":" done layer: W2_W5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ac0169a4d8048148b35b068bf2df23d"}},"metadata":{}},{"name":"stdout","text":" done layer: W2_W5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"366cbaee359f4353bede5858a5bf6f50"}},"metadata":{}},{"name":"stdout","text":" done layer: W2_W5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bc6404896724969b620890defd712f2"}},"metadata":{}},{"name":"stdout","text":" done layer: W2_W5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"179046416da0448292fb6f57228ddafb"}},"metadata":{}},{"name":"stdout","text":" done layer: W2_W5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bb8174e050b402d8aa2ad8339dea720"}},"metadata":{}},{"name":"stdout","text":" done layer: W2_W5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95dc44d498d945f4990c8ebdfac5c08c"}},"metadata":{}},{"name":"stdout","text":" done layer: W2_W5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf5452b3bd7b41d9acfe1d04c8d688bb"}},"metadata":{}},{"name":"stdout","text":" done layer: W2_W5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c7ae961903e46398b3bd64f0d84b225"}},"metadata":{}},{"name":"stdout","text":" done layer: W2_W5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dd92cb8acdb43118b5a0cc0ba9daa42"}},"metadata":{}},{"name":"stdout","text":" done layer: W2_W5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7358c3d1e92d43428c96da8d7ba7098d"}},"metadata":{}},{"name":"stdout","text":" done layer: W2_W5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"093c4313b4fd412b9689ff42d78324ed"}},"metadata":{}},{"name":"stdout","text":" done layer: W2_W5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da1b1c9723d945b4aa161a4a26f9e419"}},"metadata":{}},{"name":"stdout","text":" done layer: W2_W5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2c6524386ca4fe38a9f9aa48eff964c"}},"metadata":{}},{"name":"stdout","text":" done layer: W2_W5\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# remove all","metadata":{}},{"cell_type":"code","source":"!rm -rf /kaggle/working/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ZIP","metadata":{}},{"cell_type":"code","source":"#only for rp\n!apt-get update\n!apt-get install zip -y","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"envOutPath='/kaggle/working/InstantStyle'\n# envOutPath='/content'\n# envOutPath='/workspace'\n!zip -j instan_neg12.zip {envOutPath}/*.png\n# !zip a_images.zip {envOutPath}/B-LoRA/*.png","metadata":{"execution":{"iopub.status.busy":"2024-10-14T22:43:54.777636Z","iopub.execute_input":"2024-10-14T22:43:54.778298Z","iopub.status.idle":"2024-10-14T22:43:56.924329Z","shell.execute_reply.started":"2024-10-14T22:43:54.778258Z","shell.execute_reply":"2024-10-14T22:43:56.923200Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"  adding: colorbuilding__tower_0.3_ins_apple_W2_W5_1000.png (deflated 0%)\n  adding: colorbuilding__tower_0.3_ins_cat_W2_W5_1000.png (deflated 0%)\n  adding: colorbuilding__tower_0.3_ins_dog_W2_W5_1000.png (deflated 0%)\n  adding: colorbuilding__tower_0.3_ins_fish_W2_W5_1000.png (deflated 0%)\n  adding: colorbuilding__tower_0.3_ins_girl_W2_W5_1000.png (deflated 0%)\n  adding: colorbuilding__tower_0.5_ins_apple_W2_W5_1000.png (deflated 0%)\n  adding: colorbuilding__tower_0.5_ins_cat_W2_W5_1000.png (deflated 0%)\n  adding: colorbuilding__tower_0.5_ins_dog_W2_W5_1000.png (deflated 0%)\n  adding: colorbuilding__tower_0.5_ins_fish_W2_W5_1000.png (deflated 0%)\n  adding: colorbuilding__tower_0.5_ins_girl_W2_W5_1000.png (deflated 0%)\n  adding: colorbuilding__tower_0.7_ins_apple_W2_W5_1000.png (deflated 0%)\n  adding: colorbuilding__tower_0.7_ins_cat_W2_W5_1000.png (deflated 0%)\n  adding: colorbuilding__tower_0.7_ins_dog_W2_W5_1000.png (deflated 0%)\n  adding: colorbuilding__tower_0.7_ins_fish_W2_W5_1000.png (deflated 0%)\n  adding: colorbuilding__tower_0.7_ins_girl_W2_W5_1000.png (deflated 0%)\n","output_type":"stream"}]},{"cell_type":"code","source":"!rm {envOutPath}/*.png","metadata":{"execution":{"iopub.status.busy":"2024-10-14T22:43:59.450760Z","iopub.execute_input":"2024-10-14T22:43:59.451194Z","iopub.status.idle":"2024-10-14T22:44:00.718266Z","shell.execute_reply.started":"2024-10-14T22:43:59.451155Z","shell.execute_reply":"2024-10-14T22:44:00.716962Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"!rm {envOutPath}/*.zip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# only for test,no need to run:","metadata":{}},{"cell_type":"code","source":"!pip -q install huggingface_hub diffusers einops","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import hf_hub_download\nimport os\nip_ckpt=hf_hub_download(repo_id=\"h94/IP-Adapter\", filename=\"sdxl_models/ip-adapter_sdxl.bin\", local_dir=\"ipadapter\")\nprint(ip_ckpt)\nhf_hub_download(repo_id=\"h94/IP-Adapter\", filename=\"sdxl_models/image_encoder/config.json\", local_dir=\"ipadapter\")\nhf_hub_download(repo_id=\"h94/IP-Adapter\", filename=\"sdxl_models/image_encoder/pytorch_model.bin\", local_dir=\"ipadapter\")\nimage_encoder_file_path=hf_hub_download(repo_id=\"h94/IP-Adapter\", filename=\"sdxl_models/image_encoder/model.safetensors\", local_dir=\"ipadapter\")\n# Get the parent folder of the file\nimage_encoder_path = os.path.dirname(image_encoder_file_path)\n\n# Print the parent folder\nprint(image_encoder_path)\n# hf_hub_download(repo_id=\"h94/IP-Adapter\", filename=\"sdxl_models/image_encoder/config.json\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nbase_model_path = \"stabilityai/stable-diffusion-xl-base-1.0\"\npipe = StableDiffusionXLPipeline.from_pretrained(\n        base_model_path,\n        torch_dtype=torch.float16,\n        add_watermarker=False,\n    )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://civitai.com/api/download/models/129573 -O 3DStyle.safetensors\n!wget https://civitai.com/api/download/models/367359 -O blue_pencil-XL.safetensors\n# !wget https://civitai.com/api/download/models/163062 -O hanfuSong.safetensors","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from safetensors.torch import load_file\nimport torch\nfrom diffusers import StableDiffusionXLPipeline\n# pipeline = StableDiffusionXLPipeline.from_pretrained(\n#             \"stabilityai/stable-diffusion-xl-base-1.0\",\n#             torch_dtype=torch.float16,\n#         )\n    \n# Load the safetensors file\n# state_dict = load_file(\"hanfuSong.safetensors\")\n# state_dict = load_file(\"3DStyle.safetensors\")\nstate_dict = load_file(\"blue_pencil-XL.safetensors\")\n\n# Assuming you have a model class defined somewhere\n# model = YourModelClass()\n\n# Load the state_dict into the model\n# style_B_LoRA_sd, _ =pipeline.lora_state_dict(state_dict)\n\n# print(list(style_B_LoRA_sd.keys()))\n\n# state_dict = pipeline.unet.state_dict()\n\n# Print all the keys (names of layers/parameters)\nfor key in state_dict.keys():\n    print(key)\n# Set the model to evaluation mode\n# model.eval()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}