{"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPhBmSWtPQW/9e8LYcGNpE/","gpuType":"T4","include_colab_link":true,"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9285783,"sourceType":"datasetVersion","datasetId":5620913},{"sourceId":9423783,"sourceType":"datasetVersion","datasetId":5724153},{"sourceId":9462137,"sourceType":"datasetVersion","datasetId":5752841},{"sourceId":9466234,"sourceType":"datasetVersion","datasetId":5755856},{"sourceId":9511690,"sourceType":"datasetVersion","datasetId":5789879},{"sourceId":9512091,"sourceType":"datasetVersion","datasetId":5790176},{"sourceId":9512092,"sourceType":"datasetVersion","datasetId":5790177},{"sourceId":9513143,"sourceType":"datasetVersion","datasetId":5790972}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"032db7bcc5734b62bc8488a3e76ea526":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc9a0fe0e921460a8f93e0f6093615de","placeholder":"​","style":"IPY_MODEL_dbcadd2de119469c9ab85c21c6ac2ecf","value":"pytorch_lora_weights.safetensors: 100%"}},"07eec5a7c7fe466199fc346c8796bfad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c98f023b99004a88a76d175b5cf2b3ca","placeholder":"​","style":"IPY_MODEL_213fcd4bcdc44d7691d31146fd7c71f2","value":" 50/50 [00:41&lt;00:00,  1.18it/s]"}},"089cf9aef300478497ec2d33b2de6488":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f24a3e2c292e4451b5910b1985fc9b36","IPY_MODEL_dc7b16cc1ead496fbf64238d2c728fd6","IPY_MODEL_07eec5a7c7fe466199fc346c8796bfad"],"layout":"IPY_MODEL_7f1e0bbfeb7d45d0bf4a0cd0c73bb9bd"}},"09921502fa8047ec8b8844b5a6100b73":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0cc845e641344f34b1ed30a2fee6c144":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12174d1fdd984d1cb7c9980c3b830bb6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"138ed71eab774c17b5fdf45bf0c771bf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15064b5da9ea40e09f4ba393462d3c55":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"16b1460d350f4802b60df2564c5eeb94":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ded10261e594d8982d3c65441030fa3","max":112771568,"min":0,"orientation":"horizontal","style":"IPY_MODEL_09921502fa8047ec8b8844b5a6100b73","value":112771568}},"213fcd4bcdc44d7691d31146fd7c71f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2485389af27f436ea21153266bd60c18":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"290506b9ee024fc0a1e988161c5fb78e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2942379f00a746b98598ab960c41c8f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"340c00bb5ec746099e22ef7ab623df24":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"368399099dc044d3811115706842359c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e341920e8af4ce3a3185eeb75c89579":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4098cc496abf43aaa312c6f89b037fbe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ce3be8f85eb44829b3498c2969d645f","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f7d761e8d3c94e4eac2c520275f595a2","value":50}},"42561b7305034812956bbb65c3d135e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_138ed71eab774c17b5fdf45bf0c771bf","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bd7bf99bf4e54a32a3bceb24e008d0d9","value":7}},"45fdd2eff72646c3ab5ed190cb8a3d28":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48d6c4ab025445d9b88ba8430e9844c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48e7fbaf18e349a0a51125f488d006ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca61cf81225449df9110c7cc63e0489d","placeholder":"​","style":"IPY_MODEL_e10e2fe3a3664f71a3abac64646a9de6","value":"pytorch_lora_weights.safetensors: 100%"}},"4cf9f5754dbc4e8a9ad2ce1f463af970":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"530b3e815c93472495613163f8208b27":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_290506b9ee024fc0a1e988161c5fb78e","placeholder":"​","style":"IPY_MODEL_afeb30146d6e4f54aad5241ee754f154","value":"Loading pipeline components...: 100%"}},"57aee3d72d0448a8951572dab3aa99cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58eb022672a5428091fd576535a851fa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b81b945206e44f0bb2e6a833879bde5c","placeholder":"​","style":"IPY_MODEL_15064b5da9ea40e09f4ba393462d3c55","value":" 113M/113M [00:01&lt;00:00, 67.5MB/s]"}},"5b479a47db234b0a84c8c79cceeb6af8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ef4833ddf2646fba045816c48b4216f","placeholder":"​","style":"IPY_MODEL_941db9acb9744238bb4ce46ae66ce754","value":" 113M/113M [00:01&lt;00:00, 52.4MB/s]"}},"5c04f6e8958a4816b7165937648a55c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ded10261e594d8982d3c65441030fa3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61110bba5e0f40018325f03f53f778be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"67f7463a69274652851fff7c2a973f51":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6edf49e8e21d44e781f41851364d1a9a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dad11d2505eb47dc9d1cad2716431f1c","placeholder":"​","style":"IPY_MODEL_340c00bb5ec746099e22ef7ab623df24","value":"100%"}},"6f55876cc4e042829e02244df88366de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73747185acbc4fd3881cafde239c5e5b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73914c56785e4f2cb6c284a91f5d6d45":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7429951d2d964d3a9dc49d1eca2c9b64":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e24a00b99c5c441b93b48b6ba1f5befe","placeholder":"​","style":"IPY_MODEL_b878f327a9944f93a253b902dc101cf7","value":" 50/50 [00:39&lt;00:00,  1.26it/s]"}},"77fd9c37b9af4ef7bcc4164efa8f52c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2485389af27f436ea21153266bd60c18","placeholder":"​","style":"IPY_MODEL_57aee3d72d0448a8951572dab3aa99cc","value":"100%"}},"7a2524f23efb4c9bac484bfb38f86b78":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bb65eefdb6c40789cbf273cf9a76164","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e58379d2fd6640248377f914c6dd59dc","value":50}},"7ce3be8f85eb44829b3498c2969d645f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f1e0bbfeb7d45d0bf4a0cd0c73bb9bd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83cb6bfa5eb649cdbc3a25a9fc77907f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"941db9acb9744238bb4ce46ae66ce754":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9bb65eefdb6c40789cbf273cf9a76164":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9eeb0a1da4a34c8cb8a56832475d6b10":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ef4833ddf2646fba045816c48b4216f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a775bc86ed53464f8901901e286587aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e4674f6d6631420b8a3cd39fae926c18","IPY_MODEL_c5c51faf2aca40438488f9b07fe80269","IPY_MODEL_f8926055346d4c5195bacaaf4d7f9539"],"layout":"IPY_MODEL_e2a379f10bd246e4bcb12fc883010f88"}},"acbcd1811fb34c0d9d65b2504f78796a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afeb30146d6e4f54aad5241ee754f154":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b01e74d8a2b849c295c504ea3f9f722f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b1c363cd6b8047ccae0f48ac48849707":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6edf49e8e21d44e781f41851364d1a9a","IPY_MODEL_7a2524f23efb4c9bac484bfb38f86b78","IPY_MODEL_7429951d2d964d3a9dc49d1eca2c9b64"],"layout":"IPY_MODEL_45fdd2eff72646c3ab5ed190cb8a3d28"}},"b20cfb31bad54e859f674cb1046a1178":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b81b945206e44f0bb2e6a833879bde5c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b878f327a9944f93a253b902dc101cf7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9dd40868cb3404b844a18cff0ef6c85":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc8c3dbd56cc43b5bef14f1b9ec295da":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd7bf99bf4e54a32a3bceb24e008d0d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"be434e80ab4f447e953db06a58426ce6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_48e7fbaf18e349a0a51125f488d006ab","IPY_MODEL_fc3dc4ecaf0746a2a5809adf0e6c5521","IPY_MODEL_5b479a47db234b0a84c8c79cceeb6af8"],"layout":"IPY_MODEL_d626b49cb4be4f58a2e3b53d870a3c70"}},"c5c51faf2aca40438488f9b07fe80269":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0cc845e641344f34b1ed30a2fee6c144","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_67f7463a69274652851fff7c2a973f51","value":50}},"c98f023b99004a88a76d175b5cf2b3ca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca61cf81225449df9110c7cc63e0489d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc608343dde44fb8bbc18d83ae5b4e01":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc9a0fe0e921460a8f93e0f6093615de":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce6edb3c5a9547c9a6b98cc9ced60e7d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce7fbb60f6624726bc4d8981532ff766":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf602307c2034f35a2caf08c5cd4809b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c04f6e8958a4816b7165937648a55c7","placeholder":"​","style":"IPY_MODEL_4cf9f5754dbc4e8a9ad2ce1f463af970","value":"pytorch_lora_weights.safetensors: 100%"}},"d626b49cb4be4f58a2e3b53d870a3c70":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d71b365c82274764bd1e278d14ee2f33":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_530b3e815c93472495613163f8208b27","IPY_MODEL_42561b7305034812956bbb65c3d135e0","IPY_MODEL_face562472cc40619ad6628935e88f9f"],"layout":"IPY_MODEL_b9dd40868cb3404b844a18cff0ef6c85"}},"dac7682a49a44570a71008e81a74f38c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dad11d2505eb47dc9d1cad2716431f1c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbcadd2de119469c9ab85c21c6ac2ecf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc7b16cc1ead496fbf64238d2c728fd6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e341920e8af4ce3a3185eeb75c89579","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_61110bba5e0f40018325f03f53f778be","value":50}},"e10e2fe3a3664f71a3abac64646a9de6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e24a00b99c5c441b93b48b6ba1f5befe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2a379f10bd246e4bcb12fc883010f88":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4674f6d6631420b8a3cd39fae926c18":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce7fbb60f6624726bc4d8981532ff766","placeholder":"​","style":"IPY_MODEL_cc608343dde44fb8bbc18d83ae5b4e01","value":"100%"}},"e58379d2fd6640248377f914c6dd59dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ee9eb41c3e404f9c9ab0d0cc535975d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_faa4743625984998b0beb87f24bc2fe9","placeholder":"​","style":"IPY_MODEL_bc8c3dbd56cc43b5bef14f1b9ec295da","value":" 113M/113M [00:03&lt;00:00, 27.3MB/s]"}},"ef259f9c1c91483b844959364a9560d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_83cb6bfa5eb649cdbc3a25a9fc77907f","max":112771568,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b01e74d8a2b849c295c504ea3f9f722f","value":112771568}},"f013f710c3a34a9681481d34547fd0a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_77fd9c37b9af4ef7bcc4164efa8f52c8","IPY_MODEL_4098cc496abf43aaa312c6f89b037fbe","IPY_MODEL_fa93577a00e5439ca97b811e07cc746b"],"layout":"IPY_MODEL_73914c56785e4f2cb6c284a91f5d6d45"}},"f24a3e2c292e4451b5910b1985fc9b36":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12174d1fdd984d1cb7c9980c3b830bb6","placeholder":"​","style":"IPY_MODEL_6f55876cc4e042829e02244df88366de","value":"100%"}},"f6fd2d3680d1402989b0474d0c63f948":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_032db7bcc5734b62bc8488a3e76ea526","IPY_MODEL_ef259f9c1c91483b844959364a9560d7","IPY_MODEL_58eb022672a5428091fd576535a851fa"],"layout":"IPY_MODEL_ce6edb3c5a9547c9a6b98cc9ced60e7d"}},"f7d761e8d3c94e4eac2c520275f595a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f8926055346d4c5195bacaaf4d7f9539":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_73747185acbc4fd3881cafde239c5e5b","placeholder":"​","style":"IPY_MODEL_2942379f00a746b98598ab960c41c8f0","value":" 50/50 [00:39&lt;00:00,  1.27it/s]"}},"fa89bb27cd6f407d905e383a5fa2df42":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cf602307c2034f35a2caf08c5cd4809b","IPY_MODEL_16b1460d350f4802b60df2564c5eeb94","IPY_MODEL_ee9eb41c3e404f9c9ab0d0cc535975d6"],"layout":"IPY_MODEL_48d6c4ab025445d9b88ba8430e9844c7"}},"fa93577a00e5439ca97b811e07cc746b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_368399099dc044d3811115706842359c","placeholder":"​","style":"IPY_MODEL_9eeb0a1da4a34c8cb8a56832475d6b10","value":" 50/50 [00:40&lt;00:00,  1.22it/s]"}},"faa4743625984998b0beb87f24bc2fe9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"face562472cc40619ad6628935e88f9f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_acbcd1811fb34c0d9d65b2504f78796a","placeholder":"​","style":"IPY_MODEL_fe5c60310427449ea2d82f8513e4125e","value":" 7/7 [01:01&lt;00:00, 17.81s/it]"}},"fc3dc4ecaf0746a2a5809adf0e6c5521":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b20cfb31bad54e859f674cb1046a1178","max":112771568,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dac7682a49a44570a71008e81a74f38c","value":112771568}},"fe5c60310427449ea2d82f8513e4125e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/yardenfren1996/B-LoRA/blob/main/B_LoRA_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"colab_type":"text","id":"view-in-github"}},{"cell_type":"markdown","source":"# Initial","metadata":{}},{"cell_type":"code","source":"#0 kaggle; 1 google;2 rp \nrunENV=0\n\nif runENV==0:\n    envOutPath='/kaggle/working'\n    envInputPath='/kaggle/input'\nif runENV==1:\n    envOutPath='/content'\n    envInputPath=envOutPath\nif runENV==2:\n    envOutPath='/workspace'\n    envInputPath=envOutPath\n    #for rp\n    !pip install -q accelerate transformers wandb\n    !apt-get update\n    !apt-get install zip -y","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:17:49.428609Z","iopub.execute_input":"2024-10-01T23:17:49.428930Z","iopub.status.idle":"2024-10-01T23:17:49.439396Z","shell.execute_reply.started":"2024-10-01T23:17:49.428890Z","shell.execute_reply":"2024-10-01T23:17:49.438477Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install -q diffusers==0.25.0 bitsandbytes\n#for trainning (only need with latest version of diffusers)\n# !pip uninstall peft -y","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oE3Ymcr8wj6n","outputId":"75e638c2-af1a-4b44-8b52-fcc60ad089b5","execution":{"iopub.status.busy":"2024-10-01T23:17:59.938225Z","iopub.execute_input":"2024-10-01T23:17:59.938594Z","iopub.status.idle":"2024-10-01T23:18:20.663908Z","shell.execute_reply.started":"2024-10-01T23:17:59.938560Z","shell.execute_reply":"2024-10-01T23:18:20.662677Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"**Only run once**","metadata":{}},{"cell_type":"code","source":"#only run the first time\n!git clone https://github.com/RongWenYin/B-LoRA.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd B-LoRA","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:18:45.982584Z","iopub.execute_input":"2024-10-01T23:18:45.983014Z","iopub.status.idle":"2024-10-01T23:18:45.990677Z","shell.execute_reply.started":"2024-10-01T23:18:45.982973Z","shell.execute_reply":"2024-10-01T23:18:45.989603Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/working/B-LoRA\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Initial Params","metadata":{"id":"MP11CG8pijWh"}},{"cell_type":"code","source":"styleKey='colorpen'\nstylePath = f'img-{styleKey}'\n# stylePath = \"img-aut\"\n# stylePath = \"s-autumn\"\n    \nstyleDir = f'{envInputPath}/{stylePath}'\n# prompt_key = \"[s90]\"\nprompt_key = \"suliao\"\nlayerKey='W45'\noutput_dir = f'outputs_{layerKey}_{stylePath}'\n# output_dir = f'outputs_W25_{stylePath}'\n# output_dir = f'outputs_w5_{stylePath}'\nprint(prompt_key)\nprint(styleDir)\nprint(output_dir)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:18:57.896060Z","iopub.execute_input":"2024-10-01T23:18:57.896766Z","iopub.status.idle":"2024-10-01T23:18:57.903234Z","shell.execute_reply.started":"2024-10-01T23:18:57.896727Z","shell.execute_reply":"2024-10-01T23:18:57.902214Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"suliao\n/kaggle/input/img-colorpen\noutputs_W45_img-colorpen\n","output_type":"stream"}]},{"cell_type":"code","source":"import wandb\nwandb.login()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"#diy customer training-all blocks\n!accelerate launch train_dreambooth_b-lora_sdxl.py \\\n --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-xl-base-1.0\" \\\n --instance_data_dir=\"{styleDir}\" \\\n --output_dir=\"{output_dir}\" \\\n --instance_prompt=\"{prompt_key}\" \\\n --resolution=1024 \\\n --rank=64 \\\n --train_batch_size=1 \\\n --learning_rate=5e-5 \\\n --lr_scheduler=\"constant\" \\\n --lr_warmup_steps=0 \\\n --max_train_steps=1000 \\\n --checkpointing_steps=1000 \\\n --seed=\"0\" \\\n --gradient_checkpointing \\\n --use_8bit_adam \\\n --mixed_precision=\"fp16\" \\\n --cust_block_list=\"up_blocks.0.attentions.0 up_blocks.0.attentions.1\"\n#  --cust_block_list=\"down_blocks.2.attentions.1 up_blocks.0.attentions.1\"\n#  --cust_block_list=\"down_blocks.2.attentions.0 up_blocks.0.attentions.1\"\n#  --cust_block_list=\"up_blocks.0.attentions.1\"\n # --report_to=\"wandb\"  \\\n # --cust_block_list=\"down_blocks.2.attentions.0 down_blocks.2.attentions.1 mid_block.attentions.0 up_blocks.0.attentions.0 up_blocks.0.attentions.1 up_blocks.0.attentions.2\"\n#  --cust_block_list=\"up_blocks.0.attentions.1\"\n #  --cust_block_list=\"down_blocks.2.attentions.1 mid_block.attentions.0 up_blocks.0.attentions.0 up_blocks.0.attentions.1\"","metadata":{"execution":{"iopub.status.busy":"2024-09-30T11:58:16.335087Z","iopub.execute_input":"2024-09-30T11:58:16.335515Z","iopub.status.idle":"2024-09-30T12:43:00.948198Z","shell.execute_reply.started":"2024-09-30T11:58:16.335467Z","shell.execute_reply":"2024-09-30T12:43:00.946968Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/opt/conda/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/opt/conda/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/opt/conda/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/opt/conda/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/opt/conda/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nYou are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\nYou are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/opt/conda/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/opt/conda/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/opt/conda/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n{'thresholding', 'rescale_betas_zero_snr', 'variance_type', 'dynamic_thresholding_ratio', 'clip_sample_range'} was not found in config. Values will be initialized to default values.\n/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n{'reverse_transformer_layers_per_block', 'dropout', 'attention_type'} was not found in config. Values will be initialized to default values.\ncust_block_list::------- ['up_blocks.0.attentions.0', 'up_blocks.0.attentions.1']\nBLORA_BLOCKS::------- ['up_blocks.0.attentions.0', 'up_blocks.0.attentions.1']\ninstance_prompt::------- [s90] ||| /kaggle/input/img-watercolor\ncust_block_list::------- ['up_blocks.0.attentions.0', 'up_blocks.0.attentions.1']\nBLORA_BLOCKS::------- ['up_blocks.0.attentions.0', 'up_blocks.0.attentions.1']\ninstance_prompt::------- [s90] ||| /kaggle/input/img-watercolor\nSteps:   0%|                                           | 0/1000 [00:00<?, ?it/s][rank0]:[W930 11:59:26.026105071 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n[rank1]:[W930 11:59:26.027756012 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\nSteps: 100%|█████████| 1000/1000 [42:21<00:00,  2.53s/it, loss=0.00988, lr=5e-5]Model weights saved in outputs_W45_img-watercolor/checkpoint-1000/pytorch_lora_weights.safetensors\nSteps: 100%|██████████| 1000/1000 [42:22<00:00,  2.53s/it, loss=0.0432, lr=5e-5]Model weights saved in outputs_W45_img-watercolor/pytorch_lora_weights.safetensors\n{'feature_extractor', 'image_encoder'} was not found in config. Values will be initialized to default values.\n\nLoading pipeline components...:   0%|                     | 0/7 [00:00<?, ?it/s]\u001b[ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-xl-base-1.0.\n\nLoading pipeline components...:  14%|█▊           | 1/7 [00:00<00:02,  2.03it/s]\u001b[A{'timestep_type', 'sigma_max', 'sigma_min', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\nLoaded scheduler as EulerDiscreteScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-xl-base-1.0.\nLoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-xl-base-1.0.\n\nLoading pipeline components...:  43%|█████▌       | 3/7 [00:00<00:00,  5.79it/s]\u001b[ALoaded text_encoder_2 as CLIPTextModelWithProjection from `text_encoder_2` subfolder of stabilityai/stable-diffusion-xl-base-1.0.\n\nLoading pipeline components...:  71%|█████████▎   | 5/7 [00:02<00:01,  1.89it/s]\u001b[ALoaded tokenizer_2 as CLIPTokenizer from `tokenizer_2` subfolder of stabilityai/stable-diffusion-xl-base-1.0.\n{'reverse_transformer_layers_per_block', 'dropout', 'attention_type'} was not found in config. Values will be initialized to default values.\nLoaded unet as UNet2DConditionModel from `unet` subfolder of stabilityai/stable-diffusion-xl-base-1.0.\n\nLoading pipeline components...: 100%|█████████████| 7/7 [00:54<00:00,  7.78s/it]\u001b[A\n{'solver_type', 'thresholding', 'euler_at_final', 'use_lu_lambdas', 'lower_order_final', 'variance_type', 'solver_order', 'dynamic_thresholding_ratio', 'lambda_min_clipped', 'algorithm_type'} was not found in config. Values will be initialized to default values.\nLoading unet.\nSteps: 100%|██████████| 1000/1000 [43:30<00:00,  2.61s/it, loss=0.0432, lr=5e-5]\n[rank0]:[W930 12:42:57.325993489 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Inference Part : ","metadata":{}},{"cell_type":"code","source":"import torch\ncontent_alpha,style_alpha = 1,1.1\ndef is_belong_to_blocks(key, blocks):\n    try:\n        for g in blocks:\n            if g in key:\n#                 print('add key..',key)\n                return True\n        return False\n    except Exception as e:\n        raise type(e)(f'failed to is_belong_to_block, due to: {e}')\n\n\ndef filter_lora(state_dict, blocks_):\n    try:\n        return {k: v for k, v in state_dict.items() if is_belong_to_blocks(k, blocks_)}\n    except Exception as e:\n        raise type(e)(f'failed to filter_lora, due to: {e}')\n\n\ndef scale_lora(state_dict, alpha):\n    try:\n        return {k: v * alpha for k, v in state_dict.items()}\n    except Exception as e:\n        raise type(e)(f'failed to scale_lora, due to: {e}')\n\n\ndef get_target_modules(unet, blocks=None):\n    try:\n        if not blocks:\n            blocks = [('.').join(blk.split('.')[1:]) for blk in BLOCKS['content'] + BLOCKS['style']]\n\n        attns = [attn_processor_name.rsplit('.', 1)[0] for attn_processor_name, _ in unet.attn_processors.items() if\n                 is_belong_to_blocks(attn_processor_name, blocks)]\n\n        target_modules = [f'{attn}.{mat}' for mat in [\"to_k\", \"to_q\", \"to_v\", \"to_out.0\"] for attn in attns]\n        return target_modules\n    except Exception as e:\n        raise type(e)(f'failed to get_target_modules, due to: {e}')\n\n#down_blocks.2.attentions.0 down_blocks.2.attentions.1 \n#up_blocks.0.attentions.0 up_blocks.0.attentions.1 up_blocks.0.attentions.2\nBLOCKS_M = {\n    'content': ['unet.up_blocks.0.attentions.0'],\n    'style': ['unet.up_blocks.0.attentions.1','unet.up_blocks.0.attentions.2'],\n    'W1':['unet.down_blocks.2.attentions.0'],\n    'W2':['unet.down_blocks.2.attentions.1'],\n    'W3':['unet.mid_block.attentions.0'],\n    'W4':['unet.up_blocks.0.attentions.0'],\n    'W5':['unet.up_blocks.0.attentions.1'],\n    'W6':['unet.up_blocks.0.attentions.2'],\n    'W20':['down_blocks.2.attentions.1.transformer_blocks.0'],\n    'W21':['down_blocks.2.attentions.1.transformer_blocks.1'],\n    'W22':['down_blocks.2.attentions.1.transformer_blocks.2'],\n    'W23':['down_blocks.2.attentions.1.transformer_blocks.3'],\n    'W24':['down_blocks.2.attentions.1.transformer_blocks.4'],\n    'W25':['down_blocks.2.attentions.1.transformer_blocks.5'],\n    'W26':['down_blocks.2.attentions.1.transformer_blocks.6'],\n    'W27':['down_blocks.2.attentions.1.transformer_blocks.7'],\n    'W28':['down_blocks.2.attentions.1.transformer_blocks.8'],\n    'W29':['down_blocks.2.attentions.1.transformer_blocks.9'],\n    'W50':['unet.up_blocks.0.attentions.1.transformer_blocks.0'],\n    'W51':['unet.up_blocks.0.attentions.1.transformer_blocks.1'],\n    'W52':['unet.up_blocks.0.attentions.1.transformer_blocks.2'],\n    'W53':['unet.up_blocks.0.attentions.1.transformer_blocks.3'],\n    'W54':['unet.up_blocks.0.attentions.1.transformer_blocks.4'],\n    'W55':['unet.up_blocks.0.attentions.1.transformer_blocks.5'],\n    'W56':['unet.up_blocks.0.attentions.1.transformer_blocks.6'],\n    'W57':['unet.up_blocks.0.attentions.1.transformer_blocks.7'],\n    'W58':['unet.up_blocks.0.attentions.1.transformer_blocks.8'],\n    'W59':['unet.up_blocks.0.attentions.1.transformer_blocks.9'],\n#     'style': ['down_blocks.2.attentions.1','up_blocks.0.attentions.0','unet.up_blocks.0.attentions.1'],\n}\n\n# Function to free up GPU memory\ndef freeCache(pipeline):\n    try:\n        del pipeline  # Delete the pipeline object if it exists\n        # print(\"Pipeline deleted to free up GPU memory.\")\n    except NameError:\n        print(\"Pipeline does not exist, no need to delete.\")\n    except Exception as e:\n        print(f\"An error occurred when trying to delete pipeline: {e}\")\n    \n    torch.cuda.empty_cache()  # Clear the GPU memory\n    \n# Optionally clear cache for transformers\nimport transformers\ntransformers.utils.move_cache()\n        \ndef load_style_to_unet(pipe,layers, style_lora_model_id: str = '', content_alpha: float = 1.,\n                            style_alpha: float = 1.) -> None:\n        try:\n            layerList=layers.split('_')\n            blocks=[]\n            for lay in layerList:\n                blocks.extend(BLOCKS_M[lay])\n#             print('blocks...')\n#             print(blocks)\n            # Get Style B-LoRA SD\n            if style_lora_model_id:\n                # print('loading lora from..',style_lora_model_id)\n                style_B_LoRA_sd, _ = pipe.lora_state_dict(style_lora_model_id)\n#                 print(style_B_LoRA_sd)\n                #show all keyNames:\n#                 print(list(style_B_LoRA_sd.keys()))\n                print('use b-lorra..',blocks)\n                style_B_LoRA = filter_lora(style_B_LoRA_sd, blocks)\n                style_B_LoRA = scale_lora(style_B_LoRA, style_alpha)\n            else:\n                style_B_LoRA = {}\n\n            # Merge B-LoRAs SD\n#             res_lora = {**style_B_LoRA}\n            \n#             print('new keys..-')\n#             print(style_B_LoRA)\n#             for key in style_B_LoRA:\n#                 print(key)\n\n#             print('use b-lorra weight..-')\n#             print(style_B_LoRA['unet.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_v.lora.up.weight'])\n            # Load\n            \n            pipe.load_lora_into_unet(style_B_LoRA, None, pipe.unet)\n        except Exception as e:\n            raise type(e)(f'failed to load_b_lora_to_unet, due to: {e}')\n\n\nimport time\ndef genImagesBatch(layers, pipeline, objectNames,itemstep=1000):\n    \n    # Clear memory if necessary\n    freeCache(pipeline)\n#     time.sleep(.5)\n\n    # Initialize the pipeline\n    if pipeline is None:\n        pipeline = StableDiffusionXLPipeline.from_pretrained(\n            \"stabilityai/stable-diffusion-xl-base-1.0\",\n            vae=vae,\n            torch_dtype=torch.float16,\n        ).to(\"cuda\")\n        # print(\"Pipeline initialized.\")\n\n#         pipeline = StableDiffusionXLPipeline.from_pretrained(\n#                     \"stabilityai/stable-diffusion-xl-base-1.0\",\n#                     vae=vae,\n#                     torch_dtype=torch.float16,\n#                 )\n#         pipeline = nn.DataParallel(pipeline)\n#         pipeline = pipeline.to('cuda')\n#         print(\"Pipeline initialized using DataParallel.\")\n\n    # Load style into the model\n    load_style_to_unet(pipeline, layers, style_B_LoRA_path, content_alpha, style_alpha)\n    \n    print(f' {prompt_key} style | {layers} layer | {itemstep} step')\n\n    # Generate images\n    for objectName in objectNames:\n        prompt = f'a {objectName} in {prompt_key} style | {layers} layer '\n        # print(prompt)\n        image = pipeline(prompt, generator=torch.Generator(device=\"cuda\").manual_seed(138), num_images_per_prompt=1).images[0].resize((512, 512))\n        image.save(f'{styleKey}__{objectName}__{layerKey}__{layers}__{itemstep}.png')\n        torch.cuda.empty_cache()  # Free up GPU memory after saving each image","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:19:08.160145Z","iopub.execute_input":"2024-10-01T23:19:08.160491Z","iopub.status.idle":"2024-10-01T23:19:11.956853Z","shell.execute_reply.started":"2024-10-01T23:19:08.160459Z","shell.execute_reply":"2024-10-01T23:19:11.955749Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38ac40510f4649b4a83df1f24f60ff27"}},"metadata":{}}]},{"cell_type":"markdown","source":"# GEN IMAGES IN BATCH","metadata":{}},{"cell_type":"code","source":"from diffusers import StableDiffusionXLPipeline, AutoencoderKL\nfrom diffusers.utils import load_image, make_image_grid\nfrom PIL import Image\nimport numpy as np\nimport torch\nvae = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16, use_safetensors=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:19:11.958901Z","iopub.execute_input":"2024-10-01T23:19:11.959417Z","iopub.status.idle":"2024-10-01T23:19:28.762207Z","shell.execute_reply.started":"2024-10-01T23:19:11.959374Z","shell.execute_reply":"2024-10-01T23:19:28.761139Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/opt/conda/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/631 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba66feafce404512b34e90fd2a36dcff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d617aa4b921448cabd7991e7e72449ca"}},"metadata":{}}]},{"cell_type":"code","source":"from huggingface_hub import hf_hub_download\nimport os\n# style_B_LoRA_path=hf_hub_download(repo_id=\"ElaineYin/fangao1\", filename=\"f1_1000.safetensors\", local_dir=\"lora100\")\n# style_B_LoRA_path=hf_hub_download(repo_id=\"ElaineYin/loras\", filename=\"au_1000_W5.safetensors\", local_dir=\"loras\")\nstyle_B_LoRA_path=hf_hub_download(repo_id=\"ElaineYin/loras\", filename=\"suliao_original.safetensors\", local_dir=\"loras\")\nprint(style_B_LoRA_path)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Generate image for multiple layers :**","metadata":{}},{"cell_type":"code","source":"# output_dir = f'outputs_{stylePath}'\noutput_dir = f'outputs_{layerKey}_{stylePath}'\nprint(output_dir)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T23:41:50.890317Z","iopub.execute_input":"2024-09-30T23:41:50.890973Z","iopub.status.idle":"2024-09-30T23:41:50.895978Z","shell.execute_reply.started":"2024-09-30T23:41:50.890936Z","shell.execute_reply":"2024-09-30T23:41:50.894999Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"outputs_W45_img-watercolor\n","output_type":"stream"}]},{"cell_type":"code","source":"objectNames = [\"girl\", \"cat\", \"apple\", \"dog\", \"fish\"]\n# objectNames = [\"girl\", \"cat\", \"fish\"]\n# objectNames = [\"bike\"]\n# objectNames = [\"\",\"\"]\nlayerList=['W4_W5','W5']\n# layerList=['W2_W5']\n# layerList=['W5']\n# layerList = ['W1','W2','W3','W4','W5','W6']\n# layerList = ['W2','W5','W1_W2','W1_W5','W2_W5','W3_W5','W4_W5','W5_W6']\n# layerList = ['W1_W2','W1_W3','W1_W4','W1_W5','W1_W6','W2_W3','W2_W4','W2_W5','W2_W6','W3_W4','W3_W5','W3_W6','W4_W5','W4_W6','W5_W6']\n# layerList = ['W1','W2','W3','W4','W5','W6','W1_W2','W1_W3','W1_W4','W1_W5','W1_W6','W2_W3','W2_W4','W2_W5','W2_W6','W3_W4','W3_W5','W3_W6','W4_W5','W4_W6','W5_W6']\n# layerList = ['W1','W3','W4','W6','W1_W3','W1_W4','W1_W6','W2_W3','W2_W4','W2_W6','W3_W4','W3_W6','W4_W6']\n#\n# layerList = ['W1','W2','W3','W4','W5','W6','W1_W2','W1_W3','W1_W4','W1_W5','W1_W6','W2_W6','W3_W6','W4_W6','W5_W6']\n\n# layerList = ['W1_W2_W3','W1_W2_W4','W1_W2_W5','W1_W2_W6','W1_W3_W4','W1_W3_W5','W1_W3_W6','W1_W4_W5','W1_W4_W6','W1_W5_W6','W2_W3_W4','W2_W3_W5','W2_W3_W6','W2_W4_W5','W2_W4_W6','W2_W5_W6','W3_W4_W5','W3_W4_W6','W3_W5_W6','W4_W5_W6']\n# layerList = ['W1_W2','W1_W3','W1_W4','W1_W5','W1_W6','W2_W3','W2_W4','W2_W5','W2_W6','W3_W4','W3_W5','W3_W6','W4_W5','W4_W6','W5_W6','W1_W2_W3','W1_W2_W4','W1_W2_W5','W1_W2_W6','W1_W3_W4','W1_W3_W5','W1_W3_W6','W1_W4_W5','W1_W4_W6','W1_W5_W6','W2_W3_W4','W2_W3_W5','W2_W3_W6','W2_W4_W5','W2_W4_W6','W2_W5_W6','W3_W4_W5','W3_W4_W6','W3_W5_W6','W4_W5_W6']\n# layerList = ['W1','W2','W3','W4','W5','W6','W1_W2','W1_W3','W1_W4','W1_W5','W1_W6','W2_W3','W2_W4','W2_W5','W2_W6','W3_W4','W3_W5','W3_W6','W4_W5','W4_W6','W5_W6','W1_W2_W3','W1_W2_W4','W1_W2_W5','W1_W2_W6','W1_W3_W4','W1_W3_W5','W1_W3_W6','W1_W4_W5','W1_W4_W6','W1_W5_W6','W2_W3_W4','W2_W3_W5','W2_W3_W6','W2_W4_W5','W2_W4_W6','W2_W5_W6','W3_W4_W5','W3_W4_W6','W3_W5_W6','W4_W5_W6']\n\n#W2345:\n# layerList = ['W2','W3','W4','W5','W2_W3','W2_W4','W2_W5','W3_W4','W3_W5','W4_W5','W2_W3_W4','W2_W3_W5','W2_W4_W5','W3_W4_W5','W2_W3_W4_W5']\n# layerList = ['W2_W3','W2_W4','W2_W5','W3_W4','W3_W5','W4_W5','W2_W3_W4','W2_W3_W5','W2_W4_W5','W3_W4_W5','W2_W3_W4_W5']\nstepList=[1000]\n# stepList=[1000,1500,2000]\npipeline = None  # Start with pipeline uninitialized\nfor itemstep in stepList:    \n    style_B_LoRA_path = f'{output_dir}/checkpoint-{itemstep}/pytorch_lora_weights.safetensors'\n#     style_B_LoRA_path = f'lora100/pytorch_lora_weights.safetensors'\n    \n    print('style_B_LoRA_path:',style_B_LoRA_path)\n    # style_B_LoRA_path = f'{output_dir}/checkpoint-600/pytorch_lora_weights.safetensors'\n    #from huggingface:\n    # style_B_LoRA_path='ElaineYin/lora2345'\n    # style_B_LoRA_path='/kaggle/input/lora_f2_alllayers_1200steps/pytorch/default/1/lora_f2_alllayers_1200steps.safetensors'\n#     print(style_B_LoRA_path)\n    for layers in layerList:\n        genImagesBatch(layers, pipeline, objectNames,itemstep)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T00:32:54.042592Z","iopub.execute_input":"2024-10-01T00:32:54.043579Z","iopub.status.idle":"2024-10-01T00:40:31.431583Z","shell.execute_reply.started":"2024-10-01T00:32:54.043534Z","shell.execute_reply":"2024-10-01T00:40:31.430546Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"style_B_LoRA_path: outputs_W45_img-colorpen/checkpoint-1000/pytorch_lora_weights.safetensors\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d855fcfa6a948f78601759775523b2e"}},"metadata":{}},{"name":"stdout","text":"use b-lorra.. ['unet.up_blocks.0.attentions.0', 'unet.up_blocks.0.attentions.1']\n [s90] style | W4_W5 layer | 1000 step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d819701b25d843f18c130913537e9cf0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5778ebc84e54be882d4dfb2a41e827a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30e972cb761442fb97efa8dd5dcfc99f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85c520f17a094e1a9a41474343b3e083"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"564c4b78146b43119fba36cc3259d691"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c40204443e24cac8755a40a813a9b6f"}},"metadata":{}},{"name":"stdout","text":"use b-lorra.. ['unet.up_blocks.0.attentions.1']\n [s90] style | W5 layer | 1000 step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"091818703e464044bb79f23d20c7ca7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"929e43a37d51493d89b6d1e25005aaf5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d02c4ca2561246df9bc887cb17170bdd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa18cf1dac5d4e9787c13a2a003f1083"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81d6cb023dcb496994dab2b212d02103"}},"metadata":{}}]},{"cell_type":"markdown","source":"**Generate image for multiple (SUB) layers :**","metadata":{}},{"cell_type":"code","source":"output_dir = f'outputs_{stylePath}'\nstepList=[1000]\nobjectNames = [\"cat\",\"dog\",\"fish\",\"girl\"]\n# objectNames = [\"girl\", \"vase\", \"table\", \"tower\", \"fish\"]\n# layerList = ['W2_W5','W50','W51','W52','W53','W54','W55','W56','W57','W58','W59']\n# layerList = ['W2','W5','W50_W51_W52_W53_W54_W55','W55_W56_W57_W58_W59']\n# layerList = ['W50_W51_W52_W53_W54_W55_W56_W57_W58_W59','W51_W50_W52_W53_W54_W55_W56_W57_W58_W59','W55_W56_W57_W58_W59_W51_W50_W52_W53_W54','W51_W53_W57_W59_W55']\n\n# layerList=[\n# 'W50','W50_W51','W50_W51_W52','W50_W51_W52_W53','W50_W51_W52_W53_W54','W50_W51_W52_W53_W54_W55','W50_W51_W52_W53_W54_W55_W56','W50_W51_W52_W53_W54_W55_W56_W57','W50_W51_W52_W53_W54_W55_W56_W57_W58','W50_W51_W52_W53_W54_W55_W56_W57_W58_W59',\n# 'W51','W51_W52','W51_W52_W53','W51_W52_W53_W54','W51_W52_W53_W54_W55','W51_W52_W53_W54_W55_W56','W51_W52_W53_W54_W55_W56_W57','W51_W52_W53_W54_W55_W56_W57_W58','W51_W52_W53_W54_W55_W56_W57_W58_W59',\n# 'W52','W52_W53','W52_W53_W54','W52_W53_W54_W55','W52_W53_W54_W55_W56','W52_W53_W54_W55_W56_W57','W52_W53_W54_W55_W56_W57_W58','W52_W53_W54_W55_W56_W57_W58_W59',\n# 'W53','W53_W54','W53_W54_W55','W53_W54_W55_W56','W53_W54_W55_W56_W57','W53_W54_W55_W56_W57_W58','W53_W54_W55_W56_W57_W58_W59',\n# 'W54','W54_W55','W54_W55_W56','W54_W55_W56_W57','W54_W55_W56_W57_W58','W54_W55_W56_W57_W58_W59',\n# 'W55','W55_W56','W55_W56_W57','W55_W56_W57_W58','W55_W56_W57_W58_W59',\n# 'W56','W56_W57','W56_W57_W58','W56_W57_W58_W59',\n# 'W57','W57_W58','W57_W58_W59',\n# 'W58','W58_W59'\n# ]\n\n# layerList=[\n# 'W20','W20_W21','W20_W21_W22','W20_W21_W22_W23','W20_W21_W22_W23_W24','W20_W21_W22_W23_W24_W25','W20_W21_W22_W23_W24_W25_W26','W20_W21_W22_W23_W24_W25_W26_W27','W20_W21_W22_W23_W24_W25_W26_W27_W28','W20_W21_W22_W23_W24_W25_W26_W27_W28_W29',\n# 'W21','W21_W22','W21_W22_W23','W21_W22_W23_W24','W21_W22_W23_W24_W25','W21_W22_W23_W24_W25_W26','W21_W22_W23_W24_W25_W26_W27','W21_W22_W23_W24_W25_W26_W27_W28','W21_W22_W23_W24_W25_W26_W27_W28_W29',\n# 'W22','W22_W23','W22_W23_W24','W22_W23_W24_W25','W22_W23_W24_W25_W26','W22_W23_W24_W25_W26_W27','W22_W23_W24_W25_W26_W27_W28','W22_W23_W24_W25_W26_W27_W28_W29',\n# 'W23','W23_W24','W23_W24_W25','W23_W24_W25_W26','W23_W24_W25_W26_W27','W23_W24_W25_W26_W27_W28','W23_W24_W25_W26_W27_W28_W29',\n# 'W24','W24_W25','W24_W25_W26','W24_W25_W26_W27','W24_W25_W26_W27_W28','W24_W25_W26_W27_W28_W29',\n# 'W25','W25_W26','W25_W26_W27','W25_W26_W27_W28','W25_W26_W27_W28_W29',\n# 'W26','W26_W27','W26_W27_W28','W26_W27_W28_W29',\n# 'W27','W27_W28','W27_W28_W29',\n# 'W28','W28_W29'\n# ]\n# layerList=[\n# 'W2_W50','W2_W50_W51','W2_W50_W51_W52','W2_W50_W51_W52_W53','W2_W50_W51_W52_W53_W54','W2_W50_W51_W52_W53_W54_W55','W2_W50_W51_W52_W53_W54_W55_W56','W2_W50_W51_W52_W53_W54_W55_W56_W57','W2_W50_W51_W52_W53_W54_W55_W56_W57_W58','W2_W50_W51_W52_W53_W54_W55_W56_W57_W58_W59',\n# 'W2_W51','W2_W51_W52','W2_W51_W52_W53','W2_W51_W52_W53_W54','W2_W51_W52_W53_W54_W55','W2_W51_W52_W53_W54_W55_W56','W2_W51_W52_W53_W54_W55_W56_W57','W2_W51_W52_W53_W54_W55_W56_W57_W58','W2_W51_W52_W53_W54_W55_W56_W57_W58_W59',\n# 'W2_W52','W2_W52_W53','W2_W52_W53_W54','W2_W52_W53_W54_W55','W2_W52_W53_W54_W55_W56','W2_W52_W53_W54_W55_W56_W57','W2_W52_W53_W54_W55_W56_W57_W58','W2_W52_W53_W54_W55_W56_W57_W58_W59',\n# 'W2_W53','W2_W53_W54','W2_W53_W54_W55','W2_W53_W54_W55_W56','W2_W53_W54_W55_W56_W57','W2_W53_W54_W55_W56_W57_W58','W2_W53_W54_W55_W56_W57_W58_W59',\n# 'W2_W54','W2_W54_W55','W2_W54_W55_W56','W2_W54_W55_W56_W57','W2_W54_W55_W56_W57_W58','W2_W54_W55_W56_W57_W58_W59',\n# 'W2_W55','W2_W55_W56','W2_W55_W56_W57','W2_W55_W56_W57_W58','W2_W55_W56_W57_W58_W59',\n# 'W2_W56','W2_W56_W57','W2_W56_W57_W58','W2_W56_W57_W58_W59',\n# 'W2_W57','W2_W57_W58','W2_W57_W58_W59',\n# 'W2_W58','W2_W58_W59'\n# ]\n# layerList = ['W2','W5']\npipeline = None  # Start with pipeline uninitialized\nfor itemstep in stepList:   \n    style_B_LoRA_path = f'{output_dir}/checkpoint-{itemstep}/pytorch_lora_weights.safetensors'\n    for layers in layerList:\n\n        print('style_B_LoRA_path:',style_B_LoRA_path)\n        genImagesBatch(layers, pipeline, objectNames,itemstep)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Generate image for multiple layers :**","metadata":{}},{"cell_type":"code","source":"objectNames = [\"cat\",\"dog\"]\n# objectNames = [\"girl\", \"vase\", \"table\", \"tower\", \"fish\"]\n# layerList = ['W2_W5','W50','W51','W52','W53','W54','W55','W56','W57','W58','W59']\n# layerList = ['W2','W5','W50_W51_W52_W53_W54_W55','W55_W56_W57_W58_W59']\nlayerList = ['W2_W3_W4_W5','W5_W3_W4_W2','W5_W4_W2_W3','W3_W2_W4_W5']\n\npipeline = None  # Start with pipeline uninitialized\nfor layers in layerList:\n    genImagesBatch(layers, pipeline, objectNames)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Normal Lora\n","metadata":{}},{"cell_type":"code","source":"pipeline = StableDiffusionXLPipeline.from_pretrained(\n            \"stabilityai/stable-diffusion-xl-base-1.0\",\n            vae=vae,\n            torch_dtype=torch.float16,\n        ).to(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:20:13.406928Z","iopub.execute_input":"2024-10-01T23:20:13.407629Z","iopub.status.idle":"2024-10-01T23:21:35.947029Z","shell.execute_reply.started":"2024-10-01T23:20:13.407584Z","shell.execute_reply":"2024-10-01T23:21:35.946075Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"model_index.json:   0%|          | 0.00/609 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0092023b35de4a52a2d90467138460c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c0328c31b1c45bf974f404bbfb4280b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer/tokenizer_config.json:   0%|          | 0.00/737 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aedb2dcd355147169e80650e46ac14f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer/special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9290f4baf8cf40c7afdd3e6d139bafe9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/492M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3845b71af4e4085a322ab447854c255"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"text_encoder/config.json:   0%|          | 0.00/565 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9cf7d28d3f44b33af2f9c83ba38df82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"scheduler/scheduler_config.json:   0%|          | 0.00/479 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b9fb4aee98d43f88b49031d127dc24b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"text_encoder_2/config.json:   0%|          | 0.00/575 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc446c9ed163437cb286b990985c1855"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27fc89e12b4046f1b506d19c02ee1ccc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.78G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f75cc4dbba0145c2b6afaf9223cd5ede"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_2/tokenizer_config.json:   0%|          | 0.00/725 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dfdf4d8bd1f4319b8b721f0d06cc57b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c39bf3b864fd4720b1ca481301144269"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_2/special_tokens_map.json:   0%|          | 0.00/460 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5698f442c264830a9e8530d283a1693"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.safetensors:   0%|          | 0.00/10.3G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1aad03e1aec3498b8aec19c43a527286"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"unet/config.json:   0%|          | 0.00/1.68k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9688bbb2789d49aea243eef264c014ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2df38553cba34ff18ae21c43f510cf14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"412868ea7c444e318e0bf04c9a1d164d"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**load lora:**","metadata":{}},{"cell_type":"code","source":"# pipeline.load_lora_weights(\"ElaineYin/loras\", weight_name=\"au_1000_W5.safetensors\")\n# pipeline.load_lora_weights(\"ElaineYin/loras\", weight_name=\"suliao_original.safetensors\")\n# pipeline.load_lora_weights(\"ElaineYin/loras\", weight_name=\"suliao_s90_layer5_1000.safetensors\")\npipeline.load_lora_weights(\"ElaineYin/loras\", weight_name=\"suliao_civitai.safetensors\")\n\n\nprint('load lora done')","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:22:11.957342Z","iopub.execute_input":"2024-10-01T23:22:11.958575Z","iopub.status.idle":"2024-10-01T23:22:15.469415Z","shell.execute_reply.started":"2024-10-01T23:22:11.958532Z","shell.execute_reply":"2024-10-01T23:22:15.468258Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"suliao_civitai.safetensors:   0%|          | 0.00/228M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d949d5bce8e74fa1a293da9b7e28d748"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/diffusers/loaders/lora.py:805: FutureWarning: `_modify_text_encoder` is deprecated and will be removed in version 0.27. You are using an old version of LoRA backend. This will be deprecated in the next releases in favor of PEFT make sure to install the latest PEFT and transformers packages in the future.\n  deprecate(\"_modify_text_encoder\", \"0.27\", LORA_DEPRECATION_MESSAGE)\n/opt/conda/lib/python3.10/site-packages/diffusers/loaders/lora.py:777: FutureWarning: `_remove_text_encoder_monkey_patch_classmethod` is deprecated and will be removed in version 0.27. You are using an old version of LoRA backend. This will be deprecated in the next releases in favor of PEFT make sure to install the latest PEFT and transformers packages in the future.\n  deprecate(\"_remove_text_encoder_monkey_patch_classmethod\", \"0.27\", LORA_DEPRECATION_MESSAGE)\n","output_type":"stream"},{"name":"stdout","text":"load lora done\n","output_type":"stream"}]},{"cell_type":"code","source":"objectName=\"girl\"\n# styleKey='[s90]'\nstyleKey='suliao'\nlayers=\"W5\"\nitemstep=\"1000\"\ndiyseed=1002\nimgCnt=5\n#todo no need add this,some pics use this as prompt:\n# prompt = f'a {objectName} in {prompt_key} style | {layers} layer '\nprompt = f'a {objectName} in {prompt_key} style'\nprint(f'{prompt}  | {layers} layer ')\nfor seedin in range(imgCnt):    \n    image = pipeline(prompt, generator=torch.Generator(device=\"cuda\").manual_seed(diyseed+seedin), num_images_per_prompt=1).images[0].resize((512, 512))\n    image.save(f'{styleKey}__{objectName}__{layerKey}__{layers}__{itemstep}_{diyseed+seedin}.png')\n    torch.cuda.empty_cache()  # Free up GPU memory after saving each image\n# freeCache(pipeline)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:22:39.242295Z","iopub.execute_input":"2024-10-01T23:22:39.242697Z","iopub.status.idle":"2024-10-01T23:27:08.563660Z","shell.execute_reply.started":"2024-10-01T23:22:39.242660Z","shell.execute_reply":"2024-10-01T23:27:08.562786Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"a girl in suliao style  | W5 layer \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8f796709b8843d99aaf051e74e5bf8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f38dc9b4a2c14394a833ad0fab1339e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e58a5fcf563a4f6eadba81cfa709da9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"074765ce964d49e0ad5162fbe6c617cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"291874802429476ea2befd9271a4dc87"}},"metadata":{}}]},{"cell_type":"markdown","source":"# **Zip and download images:**","metadata":{}},{"cell_type":"code","source":"!zip -j lora_civitai.zip {envOutPath}/B-LoRA/*.png\n# !zip a_images.zip {envOutPath}/B-LoRA/*.png\n","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:28:21.882697Z","iopub.execute_input":"2024-10-01T23:28:21.883145Z","iopub.status.idle":"2024-10-01T23:28:23.164832Z","shell.execute_reply.started":"2024-10-01T23:28:21.883103Z","shell.execute_reply":"2024-10-01T23:28:23.163899Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"  adding: suliao__girl__W45__W5__1000_1002.png (deflated 0%)\n  adding: suliao__girl__W45__W5__1000_1003.png (deflated 0%)\n  adding: suliao__girl__W45__W5__1000_1004.png (deflated 0%)\n  adding: suliao__girl__W45__W5__1000_1005.png (deflated 0%)\n  adding: suliao__girl__W45__W5__1000_1006.png (deflated 0%)\n","output_type":"stream"}]},{"cell_type":"code","source":"!rm {envOutPath}/B-LoRA/*.png","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:28:25.834330Z","iopub.execute_input":"2024-10-01T23:28:25.835266Z","iopub.status.idle":"2024-10-01T23:28:27.066593Z","shell.execute_reply.started":"2024-10-01T23:28:25.835221Z","shell.execute_reply":"2024-10-01T23:28:27.065368Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"!rm {envOutPath}/B-LoRA/*.zip","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:28:00.503989Z","iopub.execute_input":"2024-10-01T23:28:00.505081Z","iopub.status.idle":"2024-10-01T23:28:01.709469Z","shell.execute_reply.started":"2024-10-01T23:28:00.505031Z","shell.execute_reply":"2024-10-01T23:28:01.708355Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"**！！！Delete all files ---Run This carefully!!!:**","metadata":{}},{"cell_type":"code","source":"!rm -rf /kaggle/working/*","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm {envOutPath}/B-LoRA/*.zip","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Generate images with multiple styles:**","metadata":{}},{"cell_type":"code","source":"from torch import nn\ndef genImagesBatchStyle(layers, pipeline, styleNames):\n    \n    # Clear memory if necessary\n    freeCache(pipeline)\n# #     time.sleep(1)\n\n    # Initialize the pipeline\n    if pipeline is None:\n        pipeline = StableDiffusionXLPipeline.from_pretrained(\n            \"stabilityai/stable-diffusion-xl-base-1.0\",\n            vae=vae,\n            torch_dtype=torch.float16,\n        ).to(\"cuda\")\n        print(\"Pipeline initialized.\")\n\n    # Load style into the model\n    load_style_to_unet(pipeline, layers, style_B_LoRA_path, content_alpha, style_alpha)\n#     time.sleep(1)\n\n    # Generate images\n    for styleName in styleNames:\n#         prompt = f'a {prompt_key} in {styleName} style'\n        prompt = f'a {styleName} of {prompt_key}'\n        print(prompt)\n        image = pipeline(prompt, generator=torch.Generator(device=\"cuda\").manual_seed(138), num_images_per_prompt=1).images[0].resize((512, 512))\n        image.save(f'{prompt_key}__{styleName}__{layers}.png')\n        torch.cuda.empty_cache()  # Free up GPU memory after saving each image\n\n    # Clean up and free memory after generating images\n    freeCache(pipeline)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Generate images with batch styles and layers list**","metadata":{}},{"cell_type":"code","source":"styleNames = [\"photorealistic portrait\", \"impressionist painting\", \"watercolor painting\", \"ukiyo-e style depiction\", \"oil painting\",\"van gogh painting\"]\n# layerList=['W2','W3']\n# layerList = ['W1','W2','W3','W4','W5','W6']\n# layerList = ['W1_W2','W1_W3','W1_W4','W1_W5','W1_W6','W2_W3','W2_W4','W2_W5','W2_W6','W3_W4','W3_W5','W3_W6','W4_W5','W4_W6','W5_W6']\n# layerList = ['W1_W2_W3','W1_W2_W4','W1_W2_W5','W1_W2_W6','W1_W3_W4','W1_W3_W5','W1_W3_W6','W1_W4_W5','W1_W4_W6','W1_W5_W6','W2_W3_W4','W2_W3_W5','W2_W3_W6','W2_W4_W5','W2_W4_W6','W2_W5_W6','W3_W4_W5','W3_W4_W6','W3_W5_W6','W4_W5_W6']\nlayerList = ['W1','W2','W3','W4','W5','W6','W1_W2','W1_W3','W1_W4','W1_W5','W1_W6','W2_W3','W2_W4','W2_W5','W2_W6','W3_W4','W3_W5','W3_W6','W4_W5','W4_W6','W5_W6','W1_W2_W3','W1_W2_W4','W1_W2_W5','W1_W2_W6','W1_W3_W4','W1_W3_W5','W1_W3_W6','W1_W4_W5','W1_W4_W6','W1_W5_W6','W2_W3_W4','W2_W3_W5','W2_W3_W6','W2_W4_W5','W2_W4_W6','W2_W5_W6','W3_W4_W5','W3_W4_W6','W3_W5_W6','W4_W5_W6']\npipeline = None  # Start with pipeline uninitialized\nfor layers in layerList:\n    genImagesBatchStyle(layers, pipeline, styleNames)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference with controlnet","metadata":{}},{"cell_type":"markdown","source":"**Only create Cany images once: **","metadata":{}},{"cell_type":"code","source":"import cv2\n\ndef genCannyImg(imgurl):\n    print('image url:',imgurl)\n    original_image=Image.open(imgurl)\n#     original_image = load_image(imgurl)\n\n    image = np.array(original_image)\n\n    low_threshold = 100\n    high_threshold = 200\n\n    image = cv2.Canny(image, low_threshold, high_threshold)\n    image = image[:, :, None]\n    image = np.concatenate([image, image, image], axis=2)\n    canny_image = Image.fromarray(image)\n    return canny_image\n\ndef genCannyImgList(sourcePath,imgList):\n    for img in imgList:\n        # canny_image=genCannyImg(\"https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/sd_controlnet/hf-logo.png\")\n        canny_image=genCannyImg(f'{sourcePath}/{img}.jpg')\n        canny_image.save(f'canny_{img}.png')\n#         imageList.append(canny_image)\n#     return imageList\nsourcePath=f'/kaggle/input/canny-original'\nobjectNames = [\"girl\", \"vase\", \"table\", \"tower\", \"fish\"]\ngenCannyImgList(sourcePath,objectNames)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from diffusers import StableDiffusionXLControlNetPipeline, ControlNetModel, AutoencoderKL\nfrom diffusers.utils import load_image, make_image_grid\nfrom PIL import Image\nimport numpy as np\nimport torch\ncontrolnet = ControlNetModel.from_pretrained(\n    \"diffusers/controlnet-canny-sdxl-1.0\",\n    torch_dtype=torch.float16,\n    use_safetensors=True\n)\nvae = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16, use_safetensors=True)\n\n# style_B_LoRA_path = f'/kaggle/input/color_building_w2345/pytorch/default/1/lora_color_building_W2345.safetensors'\nstyle_B_LoRA_path = f'ElaineYin/color_building_W2345'\nprint(style_B_LoRA_path)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# imgList=[\"https://plus.unsplash.com/premium_photo-1670282393309-70fd7f8eb1ef?fm=jpg&q=60&w=3000&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxzZWFyY2h8MXx8Z2lybCUyMHBpY3R1cmV8ZW58MHx8MHx8fDA%3D\",\n#          \"https://img.kwcdn.com/product/fancy/e4567ad7-634b-420b-9419-99bd4e56a5b2.jpg\",\n#          \"https://img.zcdn.com.au/lf/8/hash/26242/19506358/4/Dirty%2BOak%2BFinish%2BShana%2BCoffee%2BTable.jpg\",\n#          \"https://cdn.britannica.com/51/94351-050-86B70FE1/Leaning-Tower-of-Pisa-Italy.jpg\",\n#          \"https://t4.ftcdn.net/jpg/02/74/20/69/360_F_274206901_Jt1PHZTbtwne17anw5eD9oABxStNJhYT.jpg\"\n#         ]\n# objectNames = [\"dog\"]\nobjectNames = [\"girl\", \"vase\", \"table\", \"tower\", \"fish\"]\n# sourcePath=f'/kaggle/input/canny-img'\nsourcePath=f'/workspace'\ndef loadCannyImgList(sourcePath,objectNames):    \n    imageList=[]\n    for obj in objectNames:\n        image=Image.open(f'{sourcePath}/canny_{obj}.png')\n        imageList.append(image)\n    return imageList\ncanny_images=loadCannyImgList(sourcePath,objectNames)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport time\nfrom diffusers import StableDiffusionXLPipeline, AutoencoderKL\ndef genControlImagesBatch(layers, pipeline, objectNames,canny_images,controlnet=None):\n    \n    # Clear memory if necessary\n    freeCache(pipeline)\n    # time.sleep(1)\n    \n    if controlnet:\n        print('controlnet is not null')\n    # Initialize the pipeline\n    if pipeline is None:\n       # Load the pipeline\n        pipeline = StableDiffusionXLControlNetPipeline.from_pretrained(\n            \"stabilityai/stable-diffusion-xl-base-1.0\",\n            vae=vae,\n            controlnet=controlnet,\n            torch_dtype=torch.float16,\n            use_safetensors=True\n        ).to(\"cuda\")\n\n        # Enable model CPU offload for memory efficiency\n#         pipeline.enable_model_cpu_offload()\n\n        # Move pipeline to CUDA\n#         pipeline.to(\"cuda\")\n\n        # Optional: Enable attention slicing for memory efficiency during inference\n#         pipeline.enable_attention_slicing()\n\n        # Optional: Reduce memory footprint further if needed\n#         pipeline.unet.enable_xformers_memory_efficient_attention()\n        print(\"Pipeline initialized...o\")\n    load_style_to_unet(pipeline, layers, style_B_LoRA_path, content_alpha, style_alpha)\n    # time.sleep(1)\n\n    # Generate images\n    for index, objectName in enumerate(objectNames):\n        prompt = f'a {objectName} in {prompt_key} style'\n        print(prompt)\n        image = pipeline(prompt, \n                         generator=torch.Generator(device=\"cuda\").manual_seed(138),\n                         image=canny_images[index],\n                         controlnet_conditioning_scale=1.0,\n                         num_images_per_prompt=1).images[0].resize((512, 512))\n        image.save(f'{prompt_key}__{objectName}__canny__{layers}.png')\n        torch.cuda.empty_cache()  # Free up GPU memory after saving each image\n\n    # Clean up and free memory after generating images\n    freeCache(pipeline)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layerList=['W2']\n# layerList = ['W1','W2','W3','W4','W5','W6']\n# layerList = ['W1_W2','W1_W3','W1_W4','W1_W5','W1_W6','W2_W3','W2_W4','W2_W5','W2_W6','W3_W4','W3_W5','W3_W6','W4_W5','W4_W6','W5_W6']\n# layerList = ['W1_W2_W3','W1_W2_W4','W1_W2_W5','W1_W2_W6','W1_W3_W4','W1_W3_W5','W1_W3_W6','W1_W4_W5','W1_W4_W6','W1_W5_W6','W2_W3_W4','W2_W3_W5','W2_W3_W6','W2_W4_W5','W2_W4_W6','W2_W5_W6','W3_W4_W5','W3_W4_W6','W3_W5_W6','W4_W5_W6']\n# layerList = ['W1_W2','W1_W3','W1_W4','W1_W5','W1_W6','W2_W3','W2_W4','W2_W5','W2_W6','W3_W4','W3_W5','W3_W6','W4_W5','W4_W6','W5_W6','W1_W2_W3','W1_W2_W4','W1_W2_W5','W1_W2_W6','W1_W3_W4','W1_W3_W5','W1_W3_W6','W1_W4_W5','W1_W4_W6','W1_W5_W6','W2_W3_W4','W2_W3_W5','W2_W3_W6','W2_W4_W5','W2_W4_W6','W2_W5_W6','W3_W4_W5','W3_W4_W6','W3_W5_W6','W4_W5_W6']\n# layerList = ['W1','W2','W3','W4','W5','W6','W1_W2','W1_W3','W1_W4','W1_W5','W1_W6','W2_W3','W2_W4','W2_W5','W2_W6','W3_W4','W3_W5','W3_W6','W4_W5','W4_W6','W5_W6','W1_W2_W3','W1_W2_W4','W1_W2_W5','W1_W2_W6','W1_W3_W4','W1_W3_W5','W1_W3_W6','W1_W4_W5','W1_W4_W6','W1_W5_W6','W2_W3_W4','W2_W3_W5','W2_W3_W6','W2_W4_W5','W2_W4_W6','W2_W5_W6','W3_W4_W5','W3_W4_W6','W3_W5_W6','W4_W5_W6']\n\n#W2345:\n# layerList = ['W2','W3','W4','W5','W2_W3','W2_W4','W2_W5','W3_W4','W3_W5','W4_W5','W2_W3_W4','W2_W3_W5','W2_W4_W5','W3_W4_W5','W2_W3_W4_W5']\n# layerList = ['W2_W3','W2_W4','W2_W5','W3_W4','W3_W5','W4_W5','W2_W3_W4','W2_W3_W5','W2_W4_W5','W3_W4_W5','W2_W3_W4_W5']\npipeline = None  # Start with pipeline uninitialized\nfor layers in layerList:\n    genControlImagesBatch(layers, pipeline, objectNames,canny_images,controlnet=controlnet)","metadata":{},"execution_count":null,"outputs":[]}]}
